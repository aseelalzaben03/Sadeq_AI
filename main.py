# main.py

from model.model_loader import load_model_and_tokenizer, predict_label
from WebAgent.agent import web_agent_analysis

import torch

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model, tokenizer = load_model_and_tokenizer()

def combined_analysis(text):
    # ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
    prediction, confidence_model = predict_label(text, model, tokenizer)

    # ğŸŒ Ù†ØªÙŠØ¬Ø© Web Search Agent
    web_result = web_agent_analysis(text)
    confidence_web = web_result["confidence"]

    # ğŸ§  Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    combined_confidence = round((confidence_model + confidence_web) / 2, 2)

    if confidence_model > confidence_web:
        final_label = prediction  # Ø®Ø° Ø±Ø£ÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙˆØ§Ø«Ù‚ Ø£ÙƒØ«Ø±
    else:
        final_label = "Fake" if prediction == "Real" else "Real"  # Ø¹ÙƒØ³ ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù‚Ù„ÙŠÙ„Ø©

    return {
        "final_decision": final_label,
        "model_prediction": prediction,
        "model_confidence": confidence_model,
        "web_confidence": confidence_web,
        "combined_confidence": combined_confidence,
        "web_sources": web_result["sources"],
        "summary": web_result["summary"]
    }

# Ù…Ø«Ø§Ù„ ØªØ´ØºÙŠÙ„
if __name__ == "__main__":
    text = "Ø£Ø¹Ù„Ù†Øª Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø¹Ù† Ø¥Ø·Ù„Ø§Ù‚ ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¬Ø§Ù†ÙŠ Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø·Ù†ÙŠÙ† Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª."
    result = combined_analysis(text)

    print(f"\nâœ… Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {result['final_decision']} ({result['combined_confidence'] * 100:.1f}%)")
    print(f"ğŸ” ØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {result['model_prediction']} ({result['model_confidence'] * 100:.1f}%)")
    print(f"ğŸŒ Ø«Ù‚Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø±: {result['web_confidence'] * 100:.1f}%")
    print(f"ğŸ“ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø­Ø«: {result['summary']}")
    print("ğŸ“š Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø«:")
    for link in result["web_sources"]:
        print("-", link)
