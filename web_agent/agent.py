# WebAgent/agent.py

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from googlesearch import search
import torch

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ mT5 Ù…Ù† HuggingFace
tokenizer = AutoTokenizer.from_pretrained("google/mt5-small", use_fast=False)
model = AutoModelForSeq2SeqLM.from_pretrained("google/mt5-small")

def summarize_text(text):
    """ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… mT5"""
    input_ids = tokenizer("ØªÙ„Ø®ÙŠØµ: " + text, return_tensors="pt", truncation=True, max_length=512).input_ids
    summary_ids = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

def get_sources(query, num_results=5):
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Google"""
    try:
        results = list(search(query, lang="ar", num_results=num_results))
        return results
    except Exception as e:
        return ["Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«:", str(e)]

def web_agent_analysis(text):
    """
    Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµØŒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØ«Ù‚Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
    """
    summary = summarize_text(text)
    sources = get_sources(summary)

    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø±
    confidence = round(min(len(sources) / 5, 1.0), 2)

    result = {
        "summary": summary,
        "sources": sources,
        "confidence": confidence
    }
    return result

# Ù…Ø«Ø§Ù„ ØªØ´ØºÙŠÙ„ Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    input_text = "Ø£Ø¹Ù„Ù†Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© Ø¹Ù† Ø¨Ø¯Ø¡ ØªÙˆØ²ÙŠØ¹ Ù„Ù‚Ø§Ø­Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ´ÙÙŠØ§Øª Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ© Ù…Ø¬Ø§Ù†Ù‹Ø§."
    result = web_agent_analysis(input_text)

    print("ğŸ’¡ Ù…Ù„Ø®Øµ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ:\n", result["summary"])
    print("\nğŸ” Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©:")
    for link in result["sources"]:
        print("-", link)
    print("\nğŸ”’ Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©:", result["confidence"])

